{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39633887",
   "metadata": {},
   "source": [
    "## 1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from our_models import Resnet50Model, Resnet18Model, Densenet121Model\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from costume_dataset import ChestXrayDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2bc27c",
   "metadata": {},
   "source": [
    "# Preprocces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7426b0",
   "metadata": {},
   "source": [
    "## 2 Find All Available Image Files (Fixed for Your Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fada6469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files found: 112120\n"
     ]
    }
   ],
   "source": [
    "image_folders = [f\"images_{str(i).zfill(3)}_lighter/images\" for i in range(1, 13)]\n",
    "available_images = set()\n",
    "\n",
    "for folder in image_folders:\n",
    "    folder_path = os.path.join(\"nih_chest_xrays_light\", folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        for fname in os.listdir(folder_path):\n",
    "            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                available_images.add(fname)\n",
    "\n",
    "print(\"Total image files found:\", len(available_images))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16139949",
   "metadata": {},
   "source": [
    "## 3 Load CSV and Filter Valid Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859e5c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 112120\n",
      "Label distribution:\n",
      " label\n",
      "0    60361\n",
      "1    51759\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"nih_chest_xrays_light/Data_Entry_2017 copy.csv\")\n",
    "\n",
    "# Fix the extension from .png to .jpg\n",
    "df['Image Index'] = df['Image Index'].str.strip().str.replace('.png', '.jpg')\n",
    "\n",
    "# Add binary label\n",
    "df['label'] = df['Finding Labels'].apply(lambda x: 0 if x == 'No Finding' else 1)\n",
    "\n",
    "# Keep only rows where the image file actually exists\n",
    "df = df[df['Image Index'].isin(available_images)]\n",
    "\n",
    "print(\"Filtered dataset size:\", len(df))\n",
    "print(\"Label distribution:\\n\", df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c01d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n",
      "         Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
      "0  00000001_000.jpg            Cardiomegaly            0           1   \n",
      "1  00000001_001.jpg  Cardiomegaly|Emphysema            1           1   \n",
      "2  00000001_002.jpg   Cardiomegaly|Effusion            2           1   \n",
      "3  00000002_000.jpg              No Finding            0           2   \n",
      "4  00000003_000.jpg                  Hernia            0           3   \n",
      "\n",
      "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
      "0           58              M            PA                 2682     2749   \n",
      "1           58              M            PA                 2894     2729   \n",
      "2           58              M            PA                 2500     2048   \n",
      "3           81              M            PA                 2500     2048   \n",
      "4           81              F            PA                 2582     2991   \n",
      "\n",
      "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  label  \n",
      "0                        0.143  0.143          NaN      1  \n",
      "1                        0.143  0.143          NaN      1  \n",
      "2                        0.168  0.168          NaN      1  \n",
      "3                        0.171  0.171          NaN      0  \n",
      "4                        0.143  0.143          NaN      1  \n"
     ]
    }
   ],
   "source": [
    "print(\"Sample data:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69704c09",
   "metadata": {},
   "source": [
    "## 4 Define Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1408a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa27a81",
   "metadata": {},
   "source": [
    "# Explore models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb0378",
   "metadata": {},
   "source": [
    "## Create Datasets and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb3f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nih_chest_xrays_light/train_val_list copy.txt\", 'r') as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip().replace('.png', '.jpg') for x in content]\n",
    "with open(\"nih_chest_xrays_light/train_val_list copy.txt\", 'w') as f:\n",
    "    f.write('\\n'.join(content))\n",
    "\n",
    "with open(\"nih_chest_xrays_light/test_list copy.txt\", 'r') as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip().replace('.png', '.jpg') for x in content]\n",
    "with open(\"nih_chest_xrays_light/test_list copy.txt\", 'w') as f:\n",
    "    f.write('\\n'.join(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3b8436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official split sizes:\n",
      "Train: 86524\n",
      "Test: 25596\n"
     ]
    }
   ],
   "source": [
    "# Load split lists\n",
    "with open(\"nih_chest_xrays_light/train_val_list copy.txt\", 'r') as f:\n",
    "    train_files = set(x.strip() for x in f.readlines())\n",
    "\n",
    "with open(\"nih_chest_xrays_light/test_list copy.txt\", 'r') as f:\n",
    "    test_files = set(x.strip() for x in f.readlines())\n",
    "\n",
    "# Filter df using available image list\n",
    "train_df = df[df['Image Index'].isin(train_files)]\n",
    "test_df = df[df['Image Index'].isin(test_files)]\n",
    "\n",
    "print(\"Official split sizes:\")\n",
    "print(\"Train:\", len(train_df))\n",
    "print(\"Test:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.538363\n",
      "1    0.461637\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
    "\n",
    "train_dataset = ChestXrayDataset(train_df, \"nih_chest_xrays_light\", transform=transform)\n",
    "test_dataset = ChestXrayDataset(test_df, \"nih_chest_xrays_light\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(train_df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d9b8fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81c2af",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(criterion, optimizer, model, dataloader, epochs=3):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels, _ in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            # temp\n",
    "            #with torch.no_grad():\n",
    "            #    print(\"Output stats:\", outputs.min().item(), outputs.max().item())\n",
    "            # end temp\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # temp\n",
    "            #for name, param in model.named_parameters():\n",
    "            #    if param.requires_grad and param.grad is not None:\n",
    "            #        print(f\"{name}: grad norm = {param.grad.norm().item()}\")\n",
    "            # end temp \n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e04dc2",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "            correct += (preds.int() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    print(f\"Accuracy: {correct / total * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b23617",
   "metadata": {},
   "source": [
    "## ResNet-18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f37a0d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexa/Desktop/technion/semester_8/lab2/ActiveScanLab/env_ActiveScanLab/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/alexa/Desktop/technion/semester_8/lab2/ActiveScanLab/env_ActiveScanLab/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet18_model = models.resnet18(pretrained=True)\n",
    "resnet18_model.fc = nn.Linear(resnet18_model.fc.in_features, 1)\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "\n",
    "resnet18_criterion = nn.BCEWithLogitsLoss()\n",
    "resnet18_optimizer = optim.Adam(resnet18_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096974a",
   "metadata": {},
   "source": [
    "the trainning data i used in the run of this cell is not good !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c43eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2803/2803 [2:19:46<00:00,  2.99s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2803/2803 [3:34:34<00:00,  4.59s/it]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2803/2803 [3:51:01<00:00,  4.95s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5530\n",
      "Accuracy: 68.80%\n"
     ]
    }
   ],
   "source": [
    "train_model(resnet18_criterion, resnet18_optimizer, resnet18_model, train_loader, epochs=3)\n",
    "evaluate(resnet18_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffccc8c6",
   "metadata": {},
   "source": [
    "## ResNet-50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b7fd17de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexa/Desktop/technion/semester_8/lab2/ActiveScanLab/env_ActiveScanLab/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/alexa/Desktop/technion/semester_8/lab2/ActiveScanLab/env_ActiveScanLab/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define ResNet-50 Model\n",
    "resnet50_model = resnet50(pretrained=True)\n",
    "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, 1)\n",
    "resnet50_model = resnet50_model.to(device)\n",
    "\n",
    "# Freeze backbone\n",
    "for param in resnet50_model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Unfreeze only the final layer\n",
    "for param in resnet50_model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet50_criterion = nn.BCEWithLogitsLoss()\n",
    "resnet50_optimizer = optim.Adam(resnet50_model.fc.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Evaluate\n",
    "train_model(resnet50_criterion, resnet50_optimizer, resnet50_model, train_loader, epochs=4)\n",
    "evaluate(resnet50_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:58<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:59<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.6249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:12<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.6287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:11<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:06<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.6302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:10<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.6137\n",
      "Accuracy: 65.66%\n"
     ]
    }
   ],
   "source": [
    "# Take just 10000 samples to train faster\n",
    "small_train_df = train_df.sample(10000, random_state=42)\n",
    "small_train_dataset = ChestXrayDataset(small_train_df, \"nih_chest_xrays_light\", transform=transform)\n",
    "small_train_loader = DataLoader(small_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Try training for 8 epochs\n",
    "train_model(resnet50_criterion, resnet50_optimizer, resnet50_model, small_train_loader, epochs=8)\n",
    "evaluate(resnet50_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f68b05",
   "metadata": {},
   "source": [
    "# Define model_fn, Optimizer_fn and Criterion_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdda7d7",
   "metadata": {},
   "source": [
    "### Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The models from our_models.py all return logits, not probabilities.\n",
    "def BCEcriterion_fn():\n",
    "    return nn.BCEWithLogitsLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f17f4",
   "metadata": {},
   "source": [
    "### Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densenet121_fn():\n",
    "    model = Densenet121Model()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f4dec",
   "metadata": {},
   "source": [
    "### Resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da07653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_model_fn():\n",
    "    model = Resnet50Model(pretrained=True)\n",
    "    return model                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba3aa8",
   "metadata": {},
   "source": [
    "### Resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e19c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18_model_fn():\n",
    "    model = Resnet18Model(pretrained=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0aa0e",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3e3cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_fn(model, lr=1e-3):\n",
    "    return optim.Adam(model.fc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98683d8",
   "metadata": {},
   "source": [
    "# AL pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearningPipeline:\n",
    "    def __init__(self, seed,\n",
    "                 test_indices,\n",
    "                 pool_indices,\n",
    "                 train_indices,\n",
    "                 root_dir,\n",
    "                 dataset,\n",
    "                 device,\n",
    "                 model_fn,\n",
    "                 creiterion_fn,\n",
    "                 optimizer_fn,\n",
    "                 transform_fn,\n",
    "                 selection_criterion,\n",
    "                 iterations,\n",
    "                 epochs_per_iter,\n",
    "                 budget_per_iter,\n",
    "                 batch_size=32,\n",
    "                 max_train_size=60000): #NOTR: update default values later as needed\n",
    "\n",
    "        self.seed = seed\n",
    "        self.iterations = iterations\n",
    "        self.budget_per_iter = budget_per_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.max_train_size = max_train_size\n",
    "        self.root_dir = root_dir\n",
    "        self.epochs_per_iter = epochs_per_iter\n",
    "\n",
    "        # NOTE: pool_indices, train_indices and test_indices are *sets* of image filenames\n",
    "        self.pool_indices = pool_indices\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "        self.selection_criterion = selection_criterion\n",
    "\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.device = device\n",
    "        self.model_fn = model_fn\n",
    "        self.criterion_fn = creiterion_fn\n",
    "        self.optimizer_fn = optimizer_fn\n",
    "        self.transform_fn = transform_fn\n",
    "        \n",
    "        test_df = self.dataset[self.dataset['Image Index'].isin(self.test_indices)] \n",
    "        test_dataset = ChestXrayDataset(test_df, self.root_dir, transform=self.transform_fn)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        accuracy_scores = []\n",
    "        recall_scores = []\n",
    "\n",
    "        for iteration in range(self.iterations):\n",
    "            if len(self.train_indices) > self.max_train_size:\n",
    "                raise ValueError(\"The train set is larger than 600 samples\")\n",
    "\n",
    "            print(f\"Iteration {iteration + 1}/{self.iterations}\")\n",
    "\n",
    "            trained_model = self._train_model()\n",
    "            accuracy, recall = self._evaluate_model(trained_model)\n",
    "            accuracy_scores.append(accuracy)\n",
    "            recall_scores.append(recall)\n",
    "\n",
    "            if len(self.pool_indices) < self.budget_per_iter:\n",
    "                print(\"Not enough samples in pool to continue.\")\n",
    "                break\n",
    "\n",
    "            if self.selection_criterion == 'random':\n",
    "                new_selected_indices = self._random_sampling()\n",
    "            else:\n",
    "                new_selected_indices = self._custom_sampling(trained_model)\n",
    "\n",
    "            self._update_train_indices(new_selected_indices)\n",
    "            self._update_pool_indices(new_selected_indices)\n",
    "\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Recall: {recall:.4f}\")\n",
    "            print(\"----------------------------------------\")\n",
    "\n",
    "        return accuracy_scores, recall_scores\n",
    "    \n",
    "    def _train_model(self):\n",
    "        model = self.model_fn().to(self.device)\n",
    "        criterion = self.criterion_fn()\n",
    "        optimizer = self.optimizer_fn(model)\n",
    "        train_df = self.dataset[self.dataset['Image Index'].isin(self.train_indices)] \n",
    "        train_dataset = ChestXrayDataset(train_df, self.root_dir, transform=self.transform_fn)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        model.train()\n",
    "        for epoch in range(self.epochs_per_iter):\n",
    "            total_loss = 0\n",
    "            for images, labels, _ in tqdm(train_loader):\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.float().unsqueeze(1).to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        return model\n",
    "    \n",
    "    def _evaluate_model(self, model):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        true_positives = 0\n",
    "        actual_positives = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels, _ in self.test_loader:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                outputs = model(images)\n",
    "                preds = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "                correct += (preds.int() == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                true_positives += ((preds.int() == 1) & (labels == 1)).sum().item()\n",
    "                actual_positives += (labels == 1).sum().item()\n",
    "        \n",
    "        accuracy = correct / total * 100\n",
    "        recall = (true_positives / actual_positives * 100) if actual_positives > 0 else 0\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"Recall: {recall:.2f}%\")\n",
    "        \n",
    "        return accuracy, recall\n",
    "    \n",
    "    def _random_sampling(self):\n",
    "        random.seed(self.seed)\n",
    "        return set(random.sample(self.pool_indices, self.budget_per_iter))\n",
    "    \n",
    "    def _update_train_indices(self, new_selected_samples):\n",
    "        \"\"\"\n",
    "           Update the train indices by adding newly selected samples.\n",
    "           new_selected_samples should be a set of image filenames.\n",
    "        \"\"\"\n",
    "        self.train_indices.update(new_selected_samples)\n",
    "        \n",
    "    def _update_pool_indices(self, new_selected_samples):\n",
    "        \"\"\"\n",
    "           Update the pool indices by removing the newly selected samples.\n",
    "           new_selected_samples should be a set of image filenames.\n",
    "        \"\"\"\n",
    "        self.pool_indices.difference_update(new_selected_samples)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d72a6",
   "metadata": {},
   "source": [
    "# Sampling technics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e0407",
   "metadata": {},
   "source": [
    "## BADGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb31a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def badge_sampling(model, dataloader, budget):\n",
    "    \"\"\"\n",
    "    This is non checked code that performs badge sampling, generated by ChatGPT.\n",
    "    changes needed to be done:\n",
    "    1. Varify returned samples are set of image indices\n",
    "    2. Ensure that the model has a method `gradient_embedding` that returns embeddings\n",
    "    3. Ensure that the model is in evaluation mode before inference\n",
    "    \n",
    "    \n",
    "    BADGE = Batch Active learning by Diverse Gradient Embeddings\n",
    "    May improve active learning where:\n",
    "    You want both uncertainty (picking hard-to-classify points).\n",
    "    And diversity (picking a wide range of points, not duplicates).\n",
    "    The key insight is:\n",
    "    Instead of sampling based on just predictions or just diversity in feature space, sample based on the gradients you would get if you trained on the sample. \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    all_indices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, _, indices in dataloader:\n",
    "            embeddings = model.gradient_embedding(imgs)\n",
    "            all_embeddings.append(embeddings)\n",
    "            all_indices.extend(indices.numpy())\n",
    "\n",
    "    all_embeddings = np.concatenate(all_embeddings)\n",
    "\n",
    "    # Perform k-means++ clustering\n",
    "    kmeans = KMeans(n_clusters=budget, init='k-means++').fit(all_embeddings)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    chosen = []\n",
    "\n",
    "    # Choose points closest to cluster centers\n",
    "    for center in centers:\n",
    "        idx = np.argmin(np.linalg.norm(all_embeddings - center, axis=1))\n",
    "        chosen.append(all_indices[idx])\n",
    "\n",
    "    return set(chosen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2ec41",
   "metadata": {},
   "source": [
    "## something else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dee93c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab2fp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
