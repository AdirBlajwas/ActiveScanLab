{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ce8e69",
   "metadata": {},
   "source": [
    "## 0 Server and Directory Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74b1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /anaconda/envs/azureml_py310_sdkv2/bin/python\n",
      "Current working directory: /home/student/ActiveScanLab\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39633887",
   "metadata": {},
   "source": [
    "## 1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b8d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from classifier_models import Resnet50Model, Resnet18Model, Densenet121Model, BaseResnetModel\n",
    "from active_learning_models import *\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from costume_dataset import ChestXrayDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a12a1",
   "metadata": {},
   "source": [
    "## 1 Run Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2549ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files found: 112120\n",
      "Filtered dataset size: 112120\n",
      "Label distribution:\n",
      " label\n",
      "0    60361\n",
      "1    51759\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"nih_chest_xrays_light\"\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "dataset = ChestXrayDataset( dataset_path, split_type='from_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9b8fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2bc27c",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7426b0",
   "metadata": {},
   "source": [
    "## 2 Find All Available Image Files (Fixed for Your Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada6469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files found: 112120\n"
     ]
    }
   ],
   "source": [
    "# image_folders = [f\"images_{str(i).zfill(3)}_lighter/images\" for i in range(1, 13)]\n",
    "# available_images = set()\n",
    "\n",
    "# for folder in image_folders:\n",
    "#     folder_path = os.path.join(dataset_path, folder)\n",
    "#     if os.path.exists(folder_path):\n",
    "#         for fname in os.listdir(folder_path):\n",
    "#             if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                 available_images.add(fname)\n",
    "\n",
    "# print(\"Total image files found:\", len(available_images))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16139949",
   "metadata": {},
   "source": [
    "## 3 Load CSV and Filter Valid Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e5c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 112120\n",
      "Label distribution:\n",
      " label\n",
      "0    60361\n",
      "1    51759\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"nih_chest_xrays_light/Data_Entry_2017.csv\")\n",
    "\n",
    "# # Fix the extension from .png to .jpg\n",
    "# df['Image Index'] = df['Image Index'].str.strip().str.replace('.png', '.jpg')\n",
    "\n",
    "# # Add binary label\n",
    "# df['label'] = df['Finding Labels'].apply(lambda x: 0 if x == 'No Finding' else 1)\n",
    "\n",
    "# # Keep only rows where the image file actually exists\n",
    "# df = df[df['Image Index'].isin(available_images)]\n",
    "\n",
    "# print(\"Filtered dataset size:\", len(df))\n",
    "# print(\"Label distribution:\\n\", df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c01d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n",
      "         Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
      "0  00000001_000.jpg            Cardiomegaly            0           1   \n",
      "1  00000001_001.jpg  Cardiomegaly|Emphysema            1           1   \n",
      "2  00000001_002.jpg   Cardiomegaly|Effusion            2           1   \n",
      "3  00000002_000.jpg              No Finding            0           2   \n",
      "4  00000003_000.jpg                  Hernia            0           3   \n",
      "\n",
      "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
      "0           58              M            PA                 2682     2749   \n",
      "1           58              M            PA                 2894     2729   \n",
      "2           58              M            PA                 2500     2048   \n",
      "3           81              M            PA                 2500     2048   \n",
      "4           81              F            PA                 2582     2991   \n",
      "\n",
      "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  label  \n",
      "0                        0.143  0.143          NaN      1  \n",
      "1                        0.143  0.143          NaN      1  \n",
      "2                        0.168  0.168          NaN      1  \n",
      "3                        0.171  0.171          NaN      0  \n",
      "4                        0.143  0.143          NaN      1  \n"
     ]
    }
   ],
   "source": [
    "# print(\"Sample data:\\n\", df.head())\n",
    "print(\"Sample data:\\n\", dataset.df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa27a81",
   "metadata": {},
   "source": [
    "# Explore models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb0378",
   "metadata": {},
   "source": [
    "## Create Datasets and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"nih_chest_xrays_light/train_val_list.txt\", 'r') as f:\n",
    "#     content = f.readlines()\n",
    "# content = [x.strip().replace('.png', '.jpg') for x in content]\n",
    "# with open(\"nih_chest_xrays_light/train_val_list.txt\", 'w') as f:\n",
    "#     f.write('\\n'.join(content))\n",
    "\n",
    "# with open(\"nih_chest_xrays_light/test_list.txt\", 'r') as f:\n",
    "#     content = f.readlines()\n",
    "\n",
    "# content = [x.strip().replace('.png', '.jpg') for x in content]\n",
    "# with open(\"nih_chest_xrays_light/test_list.txt\", 'w') as f:\n",
    "#     f.write('\\n'.join(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b8436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official split sizes:\n",
      "Train: 86524\n",
      "Test: 25596\n"
     ]
    }
   ],
   "source": [
    "# # Load split lists\n",
    "# with open(\"nih_chest_xrays_light/train_val_list.txt\", 'r') as f:\n",
    "#     train_files = set(x.strip() for x in f.readlines())\n",
    "\n",
    "# with open(\"nih_chest_xrays_light/test_list.txt\", 'r') as f:\n",
    "#     test_files = set(x.strip() for x in f.readlines())\n",
    "\n",
    "# # Filter df using available image list\n",
    "# train_df = df[df['Image Index'].isin(train_files)]\n",
    "# test_df = df[df['Image Index'].isin(test_files)]\n",
    "\n",
    "# print(\"Official split sizes:\")\n",
    "# print(\"Train:\", len(train_df))\n",
    "# print(\"Test:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.538363\n",
      "1    0.461637\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
    "\n",
    "# train_dataset = ChestXrayDataset(train_df, \"nih_chest_xrays_light\")\n",
    "# test_dataset = ChestXrayDataset(test_df, \"nih_chest_xrays_light\")\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# print(train_df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b23617",
   "metadata": {},
   "source": [
    "## ResNet-18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37a0d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained ResNet18 model...\n"
     ]
    }
   ],
   "source": [
    "resnet18_model = Resnet18Model(optimizer='Adam', loss_function='BCEWithLogitsLoss', freeze=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c43eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataset.get_dataloader(from_split='train')\n",
    "test_loader = dataset.get_dataloader(from_split='test')\n",
    "resnet18_model.train_model(device, train_loader, epochs=3)\n",
    "resnet18_model.evaluate(device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffccc8c6",
   "metadata": {},
   "source": [
    "## ResNet-50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fd17de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained ResNet50 model...\n"
     ]
    }
   ],
   "source": [
    "# Define ResNet-50 Model\n",
    "resnet50_model = Resnet50Model(optimizer='Adam', loss_function='BCEWithLogitsLoss', freeze=True, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Evaluate Full Dataset\n",
    "train_loader = dataset.get_dataloader(from_split='train')\n",
    "test_loader = dataset.get_dataloader(from_split='test')\n",
    "\n",
    "resnet50_model.train_model(device, train_loader, epochs=4)\n",
    "resnet50_model.evaluate(device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take just 10000 samples to train faster\n",
    "# small_train_df = train_df.sample(10000, random_state=42)\n",
    "# small_train_dataset = ChestXrayDataset(small_train_df, \"nih_chest_xrays_light\")\n",
    "# small_train_loader = DataLoader(small_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "small_train_loader = dataset.get_dataloader(from_split='train', sample_size=10000)\n",
    "test_loader = dataset.get_dataloader(from_split='test')\n",
    "# Train & Evaluate Full Dataset\n",
    "resnet50_model.train_model(device, small_train_loader, epochs=4)\n",
    "resnet50_model.evaluate(device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f68b05",
   "metadata": {},
   "source": [
    "# Define model_fn, Optimizer_fn and Criterion_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdda7d7",
   "metadata": {},
   "source": [
    "### Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The models from our_models.py all return logits, not probabilities.\n",
    "def BCEcriterion_fn():\n",
    "    return nn.BCEWithLogitsLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f17f4",
   "metadata": {},
   "source": [
    "### Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densenet121_fn():\n",
    "    model = Densenet121Model()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f4dec",
   "metadata": {},
   "source": [
    "### Resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da07653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_model_fn():\n",
    "    model = Resnet50Model(pretrained=True)\n",
    "    return model                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba3aa8",
   "metadata": {},
   "source": [
    "### Resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e19c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18_model_fn():\n",
    "    model = Resnet18Model(pretrained=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0aa0e",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_fn(model, lr=1e-3):\n",
    "    return optim.Adam(model.fc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98683d8",
   "metadata": {},
   "source": [
    "# AL pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearningPipeline:\n",
    "    def __init__(self, seed,\n",
    "                 test_indices,\n",
    "                 pool_indices,\n",
    "                 train_indices,\n",
    "                 root_dir,\n",
    "                 dataset,\n",
    "                 device,\n",
    "                 model_fn,\n",
    "                 creiterion_fn,\n",
    "                 optimizer_fn,\n",
    "                 selection_criterion,\n",
    "                 iterations,\n",
    "                 epochs_per_iter,\n",
    "                 budget_per_iter,\n",
    "                 batch_size=32,\n",
    "                 max_train_size=60000): #NOTR: update default values later as needed\n",
    "\n",
    "        self.seed = seed\n",
    "        self.iterations = iterations\n",
    "        self.budget_per_iter = budget_per_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.max_train_size = max_train_size\n",
    "        self.root_dir = root_dir\n",
    "        self.epochs_per_iter = epochs_per_iter\n",
    "\n",
    "        # NOTE: pool_indices, train_indices and test_indices are *sets* of image filenames\n",
    "        self.pool_indices = pool_indices\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "        self.selection_criterion = selection_criterion\n",
    "\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.device = device\n",
    "        self.model_fn = model_fn\n",
    "        self.criterion_fn = creiterion_fn\n",
    "        self.optimizer_fn = optimizer_fn\n",
    "        \n",
    "        test_df = self.dataset[self.dataset['Image Index'].isin(self.test_indices)] \n",
    "        test_dataset = ChestXrayDataset(test_df, self.root_dir)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        accuracy_scores = []\n",
    "        recall_scores = []\n",
    "\n",
    "        for iteration in range(self.iterations):\n",
    "            if len(self.train_indices) > self.max_train_size:\n",
    "                raise ValueError(\"The train set is larger than 600 samples\")\n",
    "\n",
    "            print(f\"Iteration {iteration + 1}/{self.iterations}\")\n",
    "\n",
    "            trained_model = self._train_model()\n",
    "            accuracy, recall = self._evaluate_model(trained_model)\n",
    "            accuracy_scores.append(accuracy)\n",
    "            recall_scores.append(recall)\n",
    "\n",
    "            if len(self.pool_indices) < self.budget_per_iter:\n",
    "                print(\"Not enough samples in pool to continue.\")\n",
    "                break\n",
    "\n",
    "            if self.selection_criterion == 'random':\n",
    "                new_selected_indices = self._random_sampling()\n",
    "            else:\n",
    "                new_selected_indices = self._custom_sampling(trained_model)\n",
    "\n",
    "            self._update_train_indices(new_selected_indices)\n",
    "            self._update_pool_indices(new_selected_indices)\n",
    "\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Recall: {recall:.4f}\")\n",
    "            print(\"----------------------------------------\")\n",
    "\n",
    "        return accuracy_scores, recall_scores\n",
    "    \n",
    "    def _train_model(self):\n",
    "        model = self.model_fn().to(self.device)\n",
    "        criterion = self.criterion_fn()\n",
    "        optimizer = self.optimizer_fn(model)\n",
    "        train_df = self.dataset[self.dataset['Image Index'].isin(self.train_indices)] \n",
    "        train_dataset = ChestXrayDataset(train_df, self.root_dir)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        model.train()\n",
    "        for epoch in range(self.epochs_per_iter):\n",
    "            total_loss = 0\n",
    "            for images, labels, _ in tqdm(train_loader):\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.float().unsqueeze(1).to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        return model\n",
    "    \n",
    "    def _evaluate_model(self, model):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        true_positives = 0\n",
    "        actual_positives = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels, _ in self.test_loader:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                outputs = model(images)\n",
    "                preds = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "                correct += (preds.int() == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                true_positives += ((preds.int() == 1) & (labels == 1)).sum().item()\n",
    "                actual_positives += (labels == 1).sum().item()\n",
    "        \n",
    "        accuracy = correct / total * 100\n",
    "        recall = (true_positives / actual_positives * 100) if actual_positives > 0 else 0\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"Recall: {recall:.2f}%\")\n",
    "        \n",
    "        return accuracy, recall\n",
    "    \n",
    "    def _random_sampling(self):\n",
    "        random.seed(self.seed)\n",
    "        return set(random.sample(self.pool_indices, self.budget_per_iter))\n",
    "    \n",
    "    def _update_train_indices(self, new_selected_samples):\n",
    "        \"\"\"\n",
    "           Update the train indices by adding newly selected samples.\n",
    "           new_selected_samples should be a set of image filenames.\n",
    "        \"\"\"\n",
    "        self.train_indices.update(new_selected_samples)\n",
    "        \n",
    "    def _update_pool_indices(self, new_selected_samples):\n",
    "        \"\"\"\n",
    "           Update the pool indices by removing the newly selected samples.\n",
    "           new_selected_samples should be a set of image filenames.\n",
    "        \"\"\"\n",
    "        self.pool_indices.difference_update(new_selected_samples)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d72a6",
   "metadata": {},
   "source": [
    "# Sampling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e0407",
   "metadata": {},
   "source": [
    "## BADGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb31a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def badge_sampling(model, dataloader, budget):\n",
    "    \"\"\"\n",
    "    This is non checked code that performs badge sampling, generated by ChatGPT.\n",
    "    changes needed to be done:\n",
    "    1. Varify returned samples are set of image indices\n",
    "    2. Ensure that the model has a method `gradient_embedding` that returns embeddings\n",
    "    3. Ensure that the model is in evaluation mode before inference\n",
    "    \n",
    "    \n",
    "    BADGE = Batch Active learning by Diverse Gradient Embeddings\n",
    "    May improve active learning where:\n",
    "    You want both uncertainty (picking hard-to-classify points).\n",
    "    And diversity (picking a wide range of points, not duplicates).\n",
    "    The key insight is:\n",
    "    Instead of sampling based on just predictions or just diversity in feature space, sample based on the gradients you would get if you trained on the sample. \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    all_indices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, _, indices in dataloader:\n",
    "            embeddings = model.gradient_embedding(imgs)\n",
    "            all_embeddings.append(embeddings)\n",
    "            all_indices.extend(indices.numpy())\n",
    "\n",
    "    all_embeddings = np.concatenate(all_embeddings)\n",
    "\n",
    "    # Perform k-means++ clustering\n",
    "    kmeans = KMeans(n_clusters=budget, init='k-means++').fit(all_embeddings)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    chosen = []\n",
    "\n",
    "    # Choose points closest to cluster centers\n",
    "    for center in centers:\n",
    "        idx = np.argmin(np.linalg.norm(all_embeddings - center, axis=1))\n",
    "        chosen.append(all_indices[idx])\n",
    "\n",
    "    return set(chosen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2ec41",
   "metadata": {},
   "source": [
    "## something else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dee93c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
